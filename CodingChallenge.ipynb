{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Insight Data Engineering - Coding Challenge**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo](http://www.southernfriedscience.com/wp-content/uploads/2011/12/logo_twitter_withbird_1000_allblue.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Version = '1.0.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Read and parse the initial dataset **\n",
    "#### This is a raw twitter feed twetted by The Prime Minister of India. <br>The raw data is currently stored in text file.  We will start by storing this raw data in as an RDD, with each element of the RDD representing a data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "baseDir = os.path.join('InsightDataEngineering')\n",
    "inputPath = os.path.join('tweet_input', 'tweets.txt')\n",
    "outputPath1 = os.path.join('tweet_output', 'ft1 ')\n",
    "outputPath2 = os.path.join('tweet_output', 'ft2 ')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "fileOutput1= os.path.join(baseDir, outputPath1)\n",
    "fileOutput2= os.path.join(baseDir, outputPath2)\n",
    "numPartitions = 2\n",
    "rawData = sc.textFile(fileName, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows : 3398\n",
      "\n",
      "[u'More good news from @Wimbledon. Congrats again @mhingis. @Leander your accomplishments are truly inspiring &amp; they make us very proud.', u\"I seek to take India's ties with Tajikistan to newer heights through this visit &amp; expand the scale of cooperation. http://t.co/PYsGvoleLv\"]\n"
     ]
    }
   ],
   "source": [
    "numPoints = rawData.count()\n",
    "print \"Total Rows : \" + str(numPoints)\n",
    "print '\\n{0}'.format(rawData.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Data Pre-Processing Standards**\n",
    "1. LowerCase the tokens\n",
    "2. Ignore Non Ascii characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simpleRules(tokenlist):\n",
    "    \"\"\" A simple implementation of input string tokenization\n",
    "    Args:\n",
    "        string (str): input string\n",
    "    Returns:\n",
    "        list: a list of tokens\n",
    "    \"\"\"\n",
    "    rule = [c.lower().encode('ascii',errors='ignore') for c in tokenlist]\n",
    "    nonEmpty = [x for x in rule if len(x) > 0 ]\n",
    "    return nonEmpty\n",
    "\n",
    "tokenRDD = rawData.map(lambda x : x.split(' '))\n",
    "rulesRDD = tokenRDD.map(lambda x : simpleRules(x))\n",
    "rulesRDDCache = rulesRDD.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### ** Feature 1 : Calculate the total number of times each word has been tweeted **\n",
    "1. Counting the token Frequencies\n",
    "2. Top 20 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words in Corpus : [('the', 2202), ('to', 1621), ('of', 1597), ('&amp;', 1252), ('a', 1066), ('in', 873), ('for', 578), ('on', 544), ('i', 525), ('with', 515), ('is', 507), ('my', 464), ('our', 405), ('rt', 358), ('at', 348), ('will', 329), ('\"rt', 285), ('we', 259), ('his', 253), ('@narendramodi', 250)]\n"
     ]
    }
   ],
   "source": [
    "bagOfWords = rulesRDDCache.flatMap(lambda x : x)\n",
    "wordCount = bagOfWords.map(lambda x : (x,1)).reduceByKey(lambda a,b : (a+b))\n",
    "#wordCount.saveAsTextFile(fileOutput1);\n",
    "sortedRDD = wordCount.takeOrdered(20, lambda (key, value): -1 * (value))\n",
    "print \"Top 20 words in Corpus : \" + str(sortedRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### ** Feature 2 : Calculate the median number of unique words per tweet, Median **\n",
    "#### ** TO DO **\n",
    "1. Implemnt a windowing funtion lag \n",
    "2. Calculate average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#medianRDD.saveAsTextFile(fileOutput2);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
